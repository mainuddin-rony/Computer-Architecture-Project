# Cache Architecture: To be Inclusive or Not To Be Inclusive?
The gap between processor and memory speeds hinders the performance of Chip Multiprocessors. An efficient and high performing cache hierarchy can reduce the gap and hence ensure better processor performance. There are multiple interesting questions arise pertaining to the design of memory hierarchy. One of them is whether it should consider cache as inclusive or exclusive? Both designs have their own advantages and disadvantages with performance tradeoff. While exclusion offers bigger space for the data, simplifies the cache coherence protocol, it limits performance when the size of the largest cache is not significantly larger than the sum of the smaller caches. On the other hand, the main advantage of inclusive cache is that when external devices or other processors in a multiprocessor in a multiprocessor system wish to remove a cache line from the processor, they need only have the processor check the L2 cache. Another advantage of inclusive caches is that the larger cache can use larger cache lines, which reduces the size of the secondary cache tags. (Exclusive caches require both caches to have the same size cache lines, so that cache lines can be swapped on a L1 miss, L2 hit). 

Processors in modern days commonly follow inclusive design (Natalie, n.d.). IBM carried this tradition into the realm of CMPs by implementing it in the IBM Power4 CMP (Barosso, 2000). The general approach used by the Intel processors is for the L3 cache to be inclusive of all of the L1 and L2 caches on the chip. AMD Athlon follows exclusive cache designs. Conversely, however, Compaqâ€™s CMP design, the Piranha (Tendler et al, 2001), chose a policy of exclusion. It seems that there is no obvious choice between the exclusive and inclusive cache design. 

The goal of this project is to evaluate both exclusive and inclusive cache architecture to see which performed best in terms of miss average latency, execution time, cache hit rate for four different benchmark programs. A simulation tool gem5, has been used to simulate their behavior. The main focus of this project is to examine the performance of the cache architectures with different ratio of L1 and L2 caches size. The hypothesis I am considering for this project is with the increase of the L2 cache size, the extra effort to maintain exclusivity may not be worth it given a very minimal or no increase in L2 hit rate.

For more details please go through the project report.
